{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.baseline import Seq2Seq, Encoder, Decoder\n",
    "from data_utils.dataset import TranslationDataset\n",
    "from data_utils.lang import read_langs, PAD\n",
    "from pl_utils.pl_model import ModelWrapper\n",
    "from pl_utils.pl_dataset import PlTranslationDataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "TEST_SHARE = 0.2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", 'r') as flines:\n",
    "    all_lines = np.array(flines.readlines())\n",
    "\n",
    "test_size = int(TEST_SHARE * len(all_lines))\n",
    "train_size = len(all_lines) - test_size\n",
    "\n",
    "train_lines, val_lines = train_test_split(all_lines, test_size=TEST_SHARE, random_state=42)\n",
    "val_lines, test_lines = train_test_split(val_lines, test_size=TEST_SHARE, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_LANG, RU_LANG, _ = read_langs(\"en\", \"ru\", list(train_lines))\n",
    "\n",
    "train_dataset = TranslationDataset(list(train_lines), EN_LANG, RU_LANG)\n",
    "val_dataset = TranslationDataset(list(val_lines), EN_LANG, RU_LANG)\n",
    "test_dataset = TranslationDataset(list(test_lines), EN_LANG, RU_LANG)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(EN_LANG.vocab)\n",
    "OUTPUT_DIM = len(RU_LANG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_fn(model: nn.Module):\n",
    "    return optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=RU_LANG.vocab.get_stoi()[PAD])\n",
    "def criterion_fn(translation, target):\n",
    "    out = translation.view(-1, translation.shape[-1])\n",
    "    exp = target.view(-1)\n",
    "    return criterion(out, exp)\n",
    "\n",
    "# criterion_fn = nn.CrossEntropyLoss(ignore_index=RU_LANG.vocab.get_stoi()[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl_model = ModelWrapper(model, criterion_fn, optimizer_fn)\n",
    "pl_dataset = PlTranslationDataset(train_dataset, val_dataset, test_dataset, 128, 128)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | Seq2Seq | 20.8 M\n",
      "----------------------------------\n",
      "20.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.8 M    Total params\n",
      "83.140    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e335f54c2f4bbaa30e6fe9be636243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd45b55197374e74a1da4a0522080a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f20d5e288b4918b069f6bf4a77bd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer.fit(\n",
    "    pl_model, \n",
    "    pl_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ModelWrapper.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=model,\n",
    "    criterion_fn=criterion_fn,\n",
    "    optimizer_fn=optimizer_fn,\n",
    ")\n",
    "\n",
    "# best = ModelWrapper.load_from_checkpoint(\n",
    "#     \"/workspaces/nlp_made/src/lightning_logs/version_1/checkpoints/epoch=24-step=7825.ckpt\",\n",
    "#     model=model,\n",
    "#     criterion_fn=criterion_fn,\n",
    "#     optimizer_fn=optimizer_fn,\n",
    "# )\n",
    "\n",
    "dataloader = pl_dataset.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "\n",
    "def calc_blue(model: ModelWrapper, pl_dataset: PlTranslationDataset, device: torch.device):\n",
    "    model.eval()\n",
    "    generated_corpa = []\n",
    "    target_corpa = []\n",
    "    batch_first = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (source, target) in tqdm(dataloader):\n",
    "            translation = model.forward((source.to(device), target.to(device)), 0, teacher_forcing_ratio=0)\n",
    "            translation = translation.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            if not batch_first:\n",
    "                translation = translation.T\n",
    "                target = target.T\n",
    "\n",
    "            for gen, orig in zip(translation, target):\n",
    "                dec_gen = pl_dataset.target_lang.decode(gen)\n",
    "                dec_orig = pl_dataset.target_lang.decode(orig)\n",
    "                generated_corpa.append(dec_gen)\n",
    "                target_corpa.append([dec_orig])\n",
    "    \n",
    "    print(\"Generated sample: \", \" \".join(generated_corpa[0]))\n",
    "    print(\"Target sample: \", \" \".join(target_corpa[0][0]))\n",
    "    \n",
    "    return corpus_bleu(target_corpa, generated_corpa) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff62ef51653949bcb3d6a63b51633a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample:  отель находится в в минутах езды от центра\n",
      "Target sample:  апарт отель all suites appart hotel расположен в 5 минутах езды от аэропорта бордо\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.658671725726304"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_blue(best, pl_dataset, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-mipt-yShL7vby-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
