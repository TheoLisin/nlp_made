{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.baseline import Seq2Seq, Encoder, Decoder\n",
    "from data_utils.dataset import TranslationDataset\n",
    "from data_utils.lang import read_langs, PAD\n",
    "from pl_utils.pl_model import ModelWrapper\n",
    "from pl_utils.pl_dataset import PlTranslationDataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "TEST_SHARE = 0.2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-24 01:13:34--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12905334 (12M) [text/plain]\n",
      "Saving to: ‘data.txt’\n",
      "\n",
      "data.txt            100%[===================>]  12.31M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-05-24 01:13:34 (111 MB/s) - ‘data.txt’ saved [12905334/12905334]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", 'r') as flines:\n",
    "    all_lines = np.array(flines.readlines())\n",
    "\n",
    "test_size = int(TEST_SHARE * len(all_lines))\n",
    "train_size = len(all_lines) - test_size\n",
    "\n",
    "train_lines, val_lines = train_test_split(all_lines, test_size=TEST_SHARE, random_state=42)\n",
    "val_lines, test_lines = train_test_split(val_lines, test_size=TEST_SHARE, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_LANG, RU_LANG, _ = read_langs(\"en\", \"ru\", list(train_lines))\n",
    "\n",
    "train_dataset = TranslationDataset(list(train_lines), EN_LANG, RU_LANG)\n",
    "val_dataset = TranslationDataset(list(val_lines), EN_LANG, RU_LANG)\n",
    "test_dataset = TranslationDataset(list(test_lines), EN_LANG, RU_LANG)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(EN_LANG.vocab)\n",
    "OUTPUT_DIM = len(RU_LANG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_fn(model: nn.Module):\n",
    "    return optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=RU_LANG.vocab.get_stoi()[PAD])\n",
    "def criterion_fn(translation, target):\n",
    "    out = translation.view(-1, translation.shape[-1])\n",
    "    exp = target.view(-1)\n",
    "    return criterion(out, exp)\n",
    "\n",
    "# criterion_fn = nn.CrossEntropyLoss(ignore_index=RU_LANG.vocab.get_stoi()[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# pl_model = ModelWrapper(model, criterion_fn, optimizer_fn)\n",
    "pl_dataset = PlTranslationDataset(train_dataset, val_dataset, test_dataset, 128, 128)\n",
    "\n",
    "pl_model = ModelWrapper.load_from_checkpoint(\n",
    "    \"/workspaces/nlp_made/src/lightning_logs/version_0/checkpoints/epoch=10-step=3443.ckpt\",\n",
    "    model=model,\n",
    "    criterion_fn=criterion_fn,\n",
    "    optimizer_fn=optimizer_fn,\n",
    ")\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        checkpoint_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | Seq2Seq | 20.8 M\n",
      "----------------------------------\n",
      "20.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.8 M    Total params\n",
      "83.140    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c278792bb7e446cb4b0db68c578b05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ceb5a5d7d44236aa4a83a73d2b6bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00c422135974e19ae7a40bc1a880d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66931311729b44d98ef385843fc649da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f844747eb8499188ba13097eba4e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b819e6ebb9014f6083a406d7d270ec77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987a667e0cd94cb2b07ebfc876cf8dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8439e20e403345be96794c993d53182a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer.fit(\n",
    "    pl_model, \n",
    "    pl_dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ModelWrapper.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=model,\n",
    "    criterion_fn=criterion_fn,\n",
    "    optimizer_fn=optimizer_fn,\n",
    ")\n",
    "\n",
    "# best = ModelWrapper.load_from_checkpoint(\n",
    "#     \"/workspaces/nlp_made/src/lightning_logs/version_1/checkpoints/epoch=24-step=7825.ckpt\",\n",
    "#     model=model,\n",
    "#     criterion_fn=criterion_fn,\n",
    "#     optimizer_fn=optimizer_fn,\n",
    "# )\n",
    "\n",
    "dataloader = pl_dataset.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4defdbd242fa4ebfa8d449975e08a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample:  отель в в в от пляжа\n",
      "Target sample:  апарт отель all suites appart hotel расположен в 5 минутах езды от аэропорта бордо\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.578765058019606"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import calc_blue\n",
    "\n",
    "calc_blue(best, pl_dataset, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-mipt-yShL7vby-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
