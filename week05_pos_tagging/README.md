PoS Tagging with BiLSTM:
* Completed version:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/natural-language-processing/blob/22f_msai/week05_pos_tagging/practice_bilstm_for_pos_tagging.ipynb)

Further readings:

* Great explanation of attention and seq2seq translation by Lena Voita: https://lena-voita.github.io/nlp_course.html#preview_seq2seq_attn
* Great blog post by Jay Alammar: http://jalammar.github.io/illustrated-transformer/
