{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYvnVzA2DmIu"
   },
   "source": [
    "### Practice: text style transfer\n",
    "\n",
    "Credits: this notebook is deeply based on [YSDA NLP course notebook](https://github.com/yandexdataschool/nlp_course/tree/2022/week10_style)\n",
    "\n",
    "Hello, sitzen class A.412C!\n",
    "\n",
    "Based on your browser search history, we conclude that you have an above average skill in natural language processing. In our benevolence, we give you a chance to contribute your skills to upholding the happiest society in the universe. Are you up to the task?\n",
    "\n",
    "As you know, our most recent breakthrough was replacing 97% restaurant workers with BFGHQBERT+++ autonomous food dispensers.\n",
    "\n",
    "Yet a some radical elements failed to recognize the greater good that we brought them. They mistakenly voice their ignorant opinions about our new INGSOC-approved restaurants, brining dangerous doubt to the minds of our loyal citzens.\n",
    "\n",
    "Surely you cannot tolerate such infidelity! Our loyal citzens demand that you rectify their mistake. _You must build a model that will automatically improve their ignorant thoughts and replace them with the thoughts they should actually have._\n",
    "\n",
    "Attached below are the INGSOC-approved datasets for ignorant and correct thoughts. The scientific terminology is for wrong opinions and correct opinions is \"negative\" and \"positive\", respectively.\n",
    "\n",
    "Respond within 7 days or you will lose 3.7629 citzenship points.\n",
    "\n",
    "![img](https://ih1.redbubble.net/image.1254830934.9884/poster,504x498,f8f8f8-pad,400x240,f8f8f8.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z63QypDjVmIe",
    "outputId": "8f4319a6-cd08-43a2-c656-71cca69d5a98"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.0 -O train_negative\n",
    "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.train.1 -O train_positive\n",
    "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.0 -O dev_negative\n",
    "!wget -q https://github.com/shentianxiao/language-style-transfer/raw/master/data/yelp/sentiment.dev.1 -O dev_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQADoMFcU5cU",
    "outputId": "d57ebbec-3f2f-4f76-99c7-7781ca6d20b5"
   },
   "outputs": [],
   "source": [
    "!head -n 5 ./dev_positive\n",
    "!echo\n",
    "!head -n 5 ./dev_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MTzCt4i6BE-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device == 'cpu':\n",
    "    print(\"Fine-tuning BERT without an accelerator is not party-approved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGhzg7qKKdqX"
   },
   "source": [
    "### Part 1: Masked language model\n",
    "\n",
    "Attached below you can find the INGSOC-compliant training code that fine-tunes a BERT model for Masked Language Modeling.\n",
    "\n",
    "You shall use this model to generate positive replacements for negative tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhhZG7YMVihR"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_mlm_positive = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True).to(device).train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5Ir_RGWBWMF"
   },
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "print(\"Preparing the training data...\")\n",
    "dataset = LineByLineTextDataset(\n",
    "    file_path=\"./train_positive\", tokenizer=tokenizer, block_size=128)\n",
    "\n",
    "print(\"Dataset ready!\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_mlm_positive,\n",
    "    train_dataset=dataset, \n",
    "    data_collator=DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15),\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./bert_mlm_positive\", overwrite_output_dir=True,\n",
    "        num_train_epochs=1, per_device_train_batch_size=32,\n",
    "        save_steps=10_000, save_total_limit=2, report_to=None),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO0jC8_7OWrq"
   },
   "outputs": [],
   "source": [
    "# <Build and train a MLM for incorrect opinions>\n",
    "\n",
    "bert_mlm_negative = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True).to(device).train(True) #<...>\n",
    "\n",
    "# <A whole lot of your code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Preparing the training data...\")\n",
    "negative_dataset = LineByLineTextDataset(\n",
    "    file_path=\"./train_negative\", tokenizer=tokenizer, block_size=128)\n",
    "\n",
    "print(\"Negative dataset ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=bert_mlm_negative,\n",
    "    train_dataset=negative_dataset, \n",
    "    data_collator=DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15),\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./bert_mlm_negative\", overwrite_output_dir=True,\n",
    "        num_train_epochs=1, per_device_train_batch_size=32,\n",
    "        save_steps=10_000, save_total_limit=2, report_to=\"none\"),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_IQohMhO63b"
   },
   "source": [
    "### Part 2: Replace tokens\n",
    "\n",
    "You can now use the two masked language models to align user opinions. You can do so with the following steps:\n",
    "\n",
    "1. Find tokens where the ratio $(P_{positive}(x) + \\epsilon) / (P_{negative}(x) + \\epsilon)$ is the smallest\n",
    "2. Replace those tokens with one of $k$ most likely tokens according to $P_{positive}(x)$.\n",
    "3. Rinse, repeat\n",
    "\n",
    "You can find the full procedure at https://arxiv.org/abs/2010.01054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token = {idx: token for token, idx in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = f'great wings and decent drinks but the wait staff is {tokenizer.mask_token} !'\n",
    "batch = tokenizer([sentence], padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(batch['input_ids'][0].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {key: value.to(device) for key, value in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_positive = bert_mlm_positive(**batch)['logits']\n",
    "logits_negative = bert_mlm_negative(**batch)['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits_positive = logits_positive[0, -3].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.argsort(-mask_logits_positive)[:5]:\n",
    "    print(idx_to_token[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_logits_negative = logits_negative[0, -3].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.argsort(-mask_logits_negative)[:5]:\n",
    "    print(idx_to_token[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replacements(sentence: str, num_tokens, k_best, epsilon=1e-3):\n",
    "  \"\"\"\n",
    "  - split the sentence into tokens using the INGSOC-approved BERT tokenizer\n",
    "  - find :num_tokens: tokens with the highest ratio (see above)\n",
    "  - replace them with :k_best: words according to bert_mlm_positive\n",
    "  :return: a list of all possible strings (up to k_best * num_tokens)\n",
    "  \"\"\"\n",
    "#   <YOUR CODE HERE>\n",
    "    batch = tokenizer([sentence], padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "\n",
    "    return <...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RJptvlOTfs4"
   },
   "outputs": [],
   "source": [
    "dev_data = list(open('./dev_negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2UlAc6QToKD"
   },
   "outputs": [],
   "source": [
    "dev_data[500:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXEuVoTmTSV-"
   },
   "outputs": [],
   "source": [
    "get_replacements(\"great wings and decent drinks but the wait staff is horrible !\",\n",
    "                 num_tokens=1, k_best=2)\n",
    "# >>> [\"great wings and decent drinks but the wait staff is great !\", \"great wings and decent drinks but the wait staff is awesome !\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZvy3rECWMZB"
   },
   "source": [
    "__Final task__ - build a procedure that iteratively applies replacements, demonstrate the effectiveness of your approach with at least 10 examples to satisfy INGSOC.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "practice_style_transfer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3_research env",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
